{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Systems\n",
    "В качестве тестового задания вам предлагается проанализировать посты из ленты «ВКонтакте» и подготовить модели для предсказания конверсии из просмотра поста в различные активности, например, лайк или пересылка в личные сообщения.\n",
    "\n",
    "Датасет доступен по ссылке, это csv-таблица, где колонки text и photo содержат текст и визуал поста, а view отвечает за число просмотра. Остальные колонки содержат информацию об активностях: число лайков, число комментариев, число, когда пост скрывали или открывали, когда открывали пост отдельно и когда его пересылали в личных сообщениях.\n",
    "\n",
    "Изображения хранятся в сжатом виде, для их просмотра можно воспользоваться, например, следующим фрагментом кода:\n",
    "\n",
    "    from base64 import b64decode\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "\n",
    "    img = Image.open(BytesIO(b64decode(data.loc[img_index, \"photo\"])))\n",
    "\n",
    "### Задачи:\n",
    "\n",
    "1. Скачайте датасет и подготовьте его к работе. Проведите первичный разведывательный анализ, определитесь с активностями, с которыми будете работать. Подготовьте датасет к обучению, сформируйте нужные выборки и целевые переменные.\n",
    "Важно: в качестве задания вам надо предсказать конверсию просмотра в активность, т.е. ее вероятность. В качестве метрики рекомендуем ориентироваться на правдоподобие, но вы можете добавить свои.\n",
    "2. Эксперименты! Вы можете использовать как текст, так и изображения. Все вместе или по отдельности. Добейтесь как можно более высокого качества используя доступные open-source модели и обучая свои.\n",
    "3. Проанализируйте и сделайте выводы по полученным моделям. Сформируйте полезные советы для авторов, которые можно использовать для повышения конверсии.\n",
    "\n",
    "Оформите задание в виде репозитория на GitHub, мы будем отдельно проверять и глубину погружения в эксперименты, и качество кода. В качестве решения пришлите ссылку на репозиторий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответ на задание\n",
    "\n",
    "1. Подготовка данных и выбор активностей:\n",
    "\t\t\n",
    "\t\tЯ загрузил датасет и провёл разведывательный анализ. Выбрал следующие активности для предсказания конверсии: лайки, комментарии, скрытие, разворачивание, открытие фотографии, пересылка и прочие. Эти активности были объединены в одну метрику с помощью весов для каждой активности, а целевая переменная представляла собой отношение суммы активностей к числу просмотров.\n",
    "\n",
    "2. Целевая переменная:\n",
    "\t\t\n",
    "\t\tЦелевая переменная была рассчитана как сумма всех активностей, умноженных на их веса, и затем делённая на количество просмотров. Таким образом, предсказание конверсии представляет собой задачу регрессии.\n",
    "\n",
    "3. Модель и эксперименты:\n",
    "\t\t\n",
    "\t\tДля работы с изображениями я использовал модель ViT (Vision Transformer), извлёк эмбеддинги изображений и обучил модель CatBoostRegressor для предсказания конверсии.\n",
    "\t\tДля работы с текстом я использовал модель BERT, извлёк текстовые эмбеддинги и обучил CatBoostRegressor.\n",
    "\t\tПосле этого я объединил эмбеддинги изображений и текста и снова обучил CatBoostRegressor на объединённых данных.\n",
    "\n",
    "4. Метрика и результаты:\n",
    "\t\t\n",
    "\t\tВ качестве основной метрики я выбрал среднеквадратическую ошибку (MSE). На объединённых данных (изображения и текст) модель достигла MSE = 0.0217, что является хорошим результатом для данной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('post2ctr_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eugen\\anaconda3\\envs\\rec_sys\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\eugen\\anaconda3\\envs\\rec_sys\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "\n",
    "# Инициализация feature extractor и модели ViT\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Определение устройства (GPU или CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Перемещаем модель на GPU\n",
    "vit_model = vit_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_base64):\n",
    "    # Декодируем изображение\n",
    "    img = Image.open(BytesIO(b64decode(image_base64))).convert(\"RGB\")\n",
    "    \n",
    "    # Преобразуем изображение для подачи в модель\n",
    "    inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "    return inputs['pixel_values'].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features_batch(batch_images):\n",
    "    # Преобразуем список изображений в батч\n",
    "    batch_images_tensor = torch.stack(batch_images).to(device)\n",
    "    \n",
    "    # Извлекаем признаки с помощью ViT\n",
    "    with torch.no_grad():\n",
    "        outputs = vit_model(pixel_values=batch_images_tensor)\n",
    "    \n",
    "    # Получаем эмбеддинг изображений (среднее по последнему слою для каждого изображения)\n",
    "    batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return batch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предварительная обработка изображений\n",
    "preprocessed_images = [preprocess_image(img) for img in data['photo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры батчей\n",
    "batch_size = 32\n",
    "image_embeddings = []\n",
    "\n",
    "# Обработка изображений в батчах\n",
    "for i in range(0, len(preprocessed_images), batch_size):\n",
    "    batch_images = preprocessed_images[i:i + batch_size]\n",
    "    batch_embeddings = extract_image_features_batch(batch_images)\n",
    "    image_embeddings.append(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем все батчи в один тензор\n",
    "X = torch.cat(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переносим эмбеддинги на CPU и создаем датасет из них\n",
    "X_cpu = X.cpu().numpy()\n",
    "image_embeddings_df = pd.DataFrame(X_cpu, columns=[f'image_emb_{i}' for i in range(X_cpu.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим веса для каждой активности\n",
    "weights = {\n",
    "    'like': 1.8,           # Лайк \n",
    "    'comment': 4,          # Комментарий \n",
    "    'hide': 3,             # Скрытие поста \n",
    "    'expand': 1.4,         # Развертывание поста \n",
    "    'open_photo': 1.3,     # Открытие фото \n",
    "    'open': 1.5,           # Открытие поста \n",
    "    'share_to_message': 5  # Пересылка в личные сообщения\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_mean = {}\n",
    "for i in data.columns[1:8]:\n",
    "\tweights_mean[i] = round((1 / data[i].mean()) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 0.26,\n",
       " 'comment': 9.75,\n",
       " 'hide': 9.31,\n",
       " 'expand': 0.13,\n",
       " 'open_photo': 0.11,\n",
       " 'open': 0.17,\n",
       " 'share_to_message': 1.79}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используется словарь weights\n",
    "def calculate_weighted_conversion(row):\n",
    "    weighted_sum = 0\n",
    "    for activity, weight in weights.items():\n",
    "        weighted_sum += row[activity] * weight \n",
    "        result = weighted_sum / row['view'] if row['view'] > 0 else 0\n",
    "    return result\n",
    "\n",
    "data['weighted_conversion'] = data.apply(calculate_weighted_conversion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используется словарь weights_mean\n",
    "def calculate_weighted_conversion(row):\n",
    "    weighted_sum = 0\n",
    "    for activity, weight in weights_mean.items():\n",
    "        weighted_sum += row[activity] * weight * 10 \n",
    "        result = weighted_sum / row['view'] if row['view'] > 0 else 0\n",
    "    return result\n",
    "\n",
    "data['weighted_conversion'] = data.apply(calculate_weighted_conversion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>like</th>\n",
       "      <th>comment</th>\n",
       "      <th>hide</th>\n",
       "      <th>expand</th>\n",
       "      <th>open_photo</th>\n",
       "      <th>open</th>\n",
       "      <th>share_to_message</th>\n",
       "      <th>weighted_conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10869</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1947</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.275196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9083</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>958</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.190367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5352</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>598</td>\n",
       "      <td>430</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>0.315433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4260</td>\n",
       "      <td>539</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0.326995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5676</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>371</td>\n",
       "      <td>271</td>\n",
       "      <td>499</td>\n",
       "      <td>4</td>\n",
       "      <td>0.328013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    view  like  comment  hide  expand  open_photo  open  share_to_message  \\\n",
       "0  10869   185        0     2       0        1947    14                20   \n",
       "1   9083   227        1     7       4         958    23                 2   \n",
       "2   5352    25        5    12     598         430   114                 4   \n",
       "3   4260   539        5     3       1         138    62                24   \n",
       "4   5676   112        2     4     371         271   499                 4   \n",
       "\n",
       "   weighted_conversion  \n",
       "0             0.275196  \n",
       "1             0.190367  \n",
       "2             0.315433  \n",
       "3             0.326995  \n",
       "4             0.328013  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['view', 'like', 'comment', 'hide', 'expand', 'open_photo', 'open', 'share_to_message', 'weighted_conversion']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.concat([image_embeddings_df, data['weighted_conversion']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробовал применить AutoML для автоматического поиска моделей, но столкнулся с технической ошибкой, которую не удалось решить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train, test = train_test_split(df_image, test_size=0.2, random_state=42)\n",
    "\n",
    "task = Task('reg')\n",
    "\n",
    "automl = TabularAutoML(\n",
    "\t\ttask=task, \n",
    "\t\ttimeout=3600, \n",
    "\t\tcpu_limit=6, \n",
    "\t\tgpu_ids='0', \n",
    "\t\t# reader_params = {'n_jobs': 6, 'cv': 5, 'random_state': 42, 'verbose': 1},\n",
    "\t\tgeneral_params= {'use_algos': [['lgb', 'cb', 'nn', 'xgb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "\t'target': 'weighted_conversion'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = automl.fit_predict(train, roles=roles, verbose=1)\n",
    "test_pred = automl.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, test_pred.data[:, 0])\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_image.drop(columns=['weighted_conversion'])\n",
    "y = df_image['weighted_conversion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=3000, learning_rate=0.1, depth=6, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1711112\ttotal: 180ms\tremaining: 6m\n",
      "100:\tlearn: 0.1565290\ttotal: 3.82s\tremaining: 1m 11s\n",
      "200:\tlearn: 0.1444264\ttotal: 7.33s\tremaining: 1m 5s\n",
      "300:\tlearn: 0.1340942\ttotal: 10.7s\tremaining: 1m\n",
      "400:\tlearn: 0.1248759\ttotal: 14.1s\tremaining: 56.2s\n",
      "500:\tlearn: 0.1164777\ttotal: 17.6s\tremaining: 52.7s\n",
      "600:\tlearn: 0.1090038\ttotal: 21s\tremaining: 48.9s\n",
      "700:\tlearn: 0.1019725\ttotal: 24.4s\tremaining: 45.3s\n",
      "800:\tlearn: 0.0954302\ttotal: 27.9s\tremaining: 41.7s\n",
      "900:\tlearn: 0.0891800\ttotal: 31.3s\tremaining: 38.2s\n",
      "1000:\tlearn: 0.0835630\ttotal: 34.8s\tremaining: 34.7s\n",
      "1100:\tlearn: 0.0782189\ttotal: 38.2s\tremaining: 31.2s\n",
      "1200:\tlearn: 0.0732512\ttotal: 41.6s\tremaining: 27.7s\n",
      "1300:\tlearn: 0.0685635\ttotal: 45s\tremaining: 24.2s\n",
      "1400:\tlearn: 0.0643148\ttotal: 48.3s\tremaining: 20.7s\n",
      "1500:\tlearn: 0.0603371\ttotal: 51.7s\tremaining: 17.2s\n",
      "1600:\tlearn: 0.0564789\ttotal: 55s\tremaining: 13.7s\n",
      "1700:\tlearn: 0.0528280\ttotal: 58.4s\tremaining: 10.3s\n",
      "1800:\tlearn: 0.0494720\ttotal: 1m 1s\tremaining: 6.83s\n",
      "1900:\tlearn: 0.0463665\ttotal: 1m 5s\tremaining: 3.39s\n",
      "1999:\tlearn: 0.0435334\ttotal: 1m 8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02740636255454142"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23527.000000\n",
       "mean         0.196537\n",
       "std          0.171080\n",
       "min          0.000762\n",
       "25%          0.076025\n",
       "50%          0.149113\n",
       "75%          0.265293\n",
       "max          2.812193\n",
       "Name: weighted_conversion, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image['weighted_conversion'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE weights: 0.027470408204398132 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE weights_mean: 0.11655845174410165 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Удаляем HTML-теги\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Заменяем HTML-сущности на пробелы\n",
    "    text = re.sub(r'&[a-zA-Z0-9#]+;', ' ', text)\n",
    "    # Разделяем цифры и буквы\n",
    "    text = re.sub(r'(\\d+)([а-яА-Яa-zA-Z])', r'\\1 \\2', text)  # Цифры перед буквами\n",
    "    text = re.sub(r'([а-яА-Яa-zA-Z])(\\d+)', r'\\1 \\2', text)  # Буквы перед цифрами\n",
    "    # Удаляем специальные символы\n",
    "    text = re.sub(r'[^A-Za-zА-Яа-я0-9ёЁ.,!?;:\\s]', '', text)  # Сохраняем буквы, цифры и знаки препинания\n",
    "    # Удаляем лишние пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Применяем очистку к колонке 'text'\n",
    "data['text'] = data['text'].apply(lambda x: clean_text(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                         \n",
       "1                                                         \n",
       "2        Новость, конечно, старенькая, но все равно инт...\n",
       "3                                  Фантазийные бриллианты.\n",
       "4        Сегодня на стадионе Динамо прошли соревнования...\n",
       "                               ...                        \n",
       "23522                       Тамара, выиграет в 24 сезоне ?\n",
       "23523    Продажи Manor Lords превысили 1 млн копий. Сре...\n",
       "23524                                                     \n",
       "23525    Магическая фраза: Уже оплачено Позвольте себе ...\n",
       "23526          Старонемецкая пастушья собака Овечий пудель\n",
       "Name: text, Length: 23527, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eugen\\anaconda3\\envs\\rec_sys\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Загружаем предобученный BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    # Проверяем, что текст является строкой\n",
    "    if isinstance(text, str):\n",
    "        # Токенизация текста\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Input text must be a string.\")\n",
    "\n",
    "    # Извлекаем признаки с помощью BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    # Получаем эмбеддинг текста (например, среднее по последнему слою)\n",
    "    text_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = [torch.tensor(extract_text_features(str(txt))) for txt in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "text_features_np = np.array(text_features)\n",
    "text_embeddings_df = pd.DataFrame(text_features_np, columns=[f'text_emb_{i}' for i in range(text_features_np.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.concat([text_embeddings_df, data['weighted_conversion']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1681594\ttotal: 41.1ms\tremaining: 1m 22s\n",
      "100:\tlearn: 0.1399215\ttotal: 3.56s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.1283066\ttotal: 7.03s\tremaining: 1m 2s\n",
      "300:\tlearn: 0.1195092\ttotal: 10.4s\tremaining: 59s\n",
      "400:\tlearn: 0.1118486\ttotal: 13.8s\tremaining: 55.1s\n",
      "500:\tlearn: 0.1052056\ttotal: 17.2s\tremaining: 51.5s\n",
      "600:\tlearn: 0.0992370\ttotal: 20.6s\tremaining: 48s\n",
      "700:\tlearn: 0.0940507\ttotal: 24s\tremaining: 44.4s\n",
      "800:\tlearn: 0.0890800\ttotal: 27.4s\tremaining: 41s\n",
      "900:\tlearn: 0.0848134\ttotal: 30.8s\tremaining: 37.5s\n",
      "1000:\tlearn: 0.0811201\ttotal: 34.2s\tremaining: 34.2s\n",
      "1100:\tlearn: 0.0775740\ttotal: 37.7s\tremaining: 30.7s\n",
      "1200:\tlearn: 0.0743590\ttotal: 41.1s\tremaining: 27.3s\n",
      "1300:\tlearn: 0.0714585\ttotal: 44.5s\tremaining: 23.9s\n",
      "1400:\tlearn: 0.0688446\ttotal: 47.9s\tremaining: 20.5s\n",
      "1500:\tlearn: 0.0664760\ttotal: 51.3s\tremaining: 17.1s\n",
      "1600:\tlearn: 0.0643038\ttotal: 54.8s\tremaining: 13.7s\n",
      "1700:\tlearn: 0.0624416\ttotal: 58.2s\tremaining: 10.2s\n",
      "1800:\tlearn: 0.0607378\ttotal: 1m 1s\tremaining: 6.81s\n",
      "1900:\tlearn: 0.0592797\ttotal: 1m 5s\tremaining: 3.4s\n",
      "1999:\tlearn: 0.0579700\ttotal: 1m 8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "X = df_text.drop(columns=['weighted_conversion'])\n",
    "y = df_text['weighted_conversion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02244703374582864"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE weights: 0.02244703374582864"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE weights_mean: 0.11835769817232832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_image = pd.concat([df_text.drop(columns='weighted_conversion'), df_image], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1682674\ttotal: 73.2ms\tremaining: 3m 39s\n",
      "100:\tlearn: 0.1375994\ttotal: 7.13s\tremaining: 3m 24s\n",
      "200:\tlearn: 0.1246470\ttotal: 13.8s\tremaining: 3m 11s\n",
      "300:\tlearn: 0.1138938\ttotal: 20.4s\tremaining: 3m 2s\n",
      "400:\tlearn: 0.1052671\ttotal: 26.9s\tremaining: 2m 54s\n",
      "500:\tlearn: 0.0973995\ttotal: 33.5s\tremaining: 2m 47s\n",
      "600:\tlearn: 0.0905218\ttotal: 40.2s\tremaining: 2m 40s\n",
      "700:\tlearn: 0.0842650\ttotal: 46.8s\tremaining: 2m 33s\n",
      "800:\tlearn: 0.0784789\ttotal: 53.5s\tremaining: 2m 26s\n",
      "900:\tlearn: 0.0731775\ttotal: 1m\tremaining: 2m 19s\n",
      "1000:\tlearn: 0.0684116\ttotal: 1m 6s\tremaining: 2m 13s\n",
      "1100:\tlearn: 0.0638981\ttotal: 1m 13s\tremaining: 2m 6s\n",
      "1200:\tlearn: 0.0597755\ttotal: 1m 20s\tremaining: 2m\n",
      "1300:\tlearn: 0.0559463\ttotal: 1m 26s\tremaining: 1m 53s\n",
      "1400:\tlearn: 0.0521293\ttotal: 1m 33s\tremaining: 1m 46s\n",
      "1500:\tlearn: 0.0487811\ttotal: 1m 40s\tremaining: 1m 40s\n",
      "1600:\tlearn: 0.0455337\ttotal: 1m 47s\tremaining: 1m 33s\n",
      "1700:\tlearn: 0.0425675\ttotal: 1m 53s\tremaining: 1m 26s\n",
      "1800:\tlearn: 0.0398767\ttotal: 2m\tremaining: 1m 20s\n",
      "1900:\tlearn: 0.0373216\ttotal: 2m 7s\tremaining: 1m 13s\n",
      "2000:\tlearn: 0.0349690\ttotal: 2m 14s\tremaining: 1m 7s\n",
      "2100:\tlearn: 0.0327104\ttotal: 2m 21s\tremaining: 1m\n",
      "2200:\tlearn: 0.0306515\ttotal: 2m 27s\tremaining: 53.6s\n",
      "2300:\tlearn: 0.0287366\ttotal: 2m 34s\tremaining: 46.9s\n",
      "2400:\tlearn: 0.0268648\ttotal: 2m 41s\tremaining: 40.2s\n",
      "2500:\tlearn: 0.0251439\ttotal: 2m 47s\tremaining: 33.5s\n",
      "2600:\tlearn: 0.0235828\ttotal: 2m 54s\tremaining: 26.8s\n",
      "2700:\tlearn: 0.0221039\ttotal: 3m 1s\tremaining: 20.1s\n",
      "2800:\tlearn: 0.0207269\ttotal: 3m 8s\tremaining: 13.4s\n",
      "2900:\tlearn: 0.0194247\ttotal: 3m 14s\tremaining: 6.65s\n",
      "2999:\tlearn: 0.0182656\ttotal: 3m 21s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "X = df_text_image.drop(columns=['weighted_conversion'])\n",
    "y = df_text_image['weighted_conversion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02179526188872042"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE text + image: 0.02179526188872042"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec_sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
